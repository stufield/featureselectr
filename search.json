[{"path":"https://stufield.github.io/featureselectr/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 featureselectr authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://stufield.github.io/featureselectr/SUPPORT.html","id":null,"dir":"","previous_headings":"","what":"Getting help with featureselectr","title":"Getting help with featureselectr","text":"Thanks using featureselectr! filing issue, places explore pieces put together make process smooth possible.","code":""},{"path":"https://stufield.github.io/featureselectr/SUPPORT.html","id":"make-a-reprex","dir":"","previous_headings":"","what":"Make a reprex","title":"Getting help with featureselectr","text":"can’t reproduce bug, can’t fix ! Start making minimal reproducible example using reprex package. haven’t heard used reprex , ’re treat! Seriously, reprex make R-question-asking endeavors easier (excellent ROI five ten minutes ’ll take learn ’s ). additional reprex pointers, check Get help!.","code":""},{"path":"https://stufield.github.io/featureselectr/SUPPORT.html","id":"where-to-ask","dir":"","previous_headings":"","what":"Where to ask?","title":"Getting help with featureselectr","text":"Armed reprex, next step figure ask: ’s question: start community.rstudio.com /StackOverflow. people answer questions. ’s bug: ’re right place -> file issue. ’re sure: let community help figure ! problem bug feature request, can easily return report . opening new issue, sure search issues pull requests make sure bug hasn’t reported /already fixed development version. default, search pre-populated :issue :open. can edit qualifiers, :pr, :closed, etc., needed, e.g. ’d simply remove :open search issues repo, open closed.","code":""},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"two-primary-functions-in-featureselectr","dir":"Articles","previous_headings":"","what":"Two primary functions in featureselectr","title":"Introduction to featureselectr","text":"Sets feature selection object containing search information. Performs actual search.","code":""},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"search-type-helpers","dir":"Articles","previous_headings":"Two primary functions in featureselectr","what":"Search Type Helpers","title":"Introduction to featureselectr","text":"two main search types choose . See ?search_type.","code":"search_type_forward_model()   # Forward stepwise #> ── Forward Search ──────────────────────────────────────────────────── #> • display_name  'Forward Stepwise Model Search' #> • max_steps     20 #> ──────────────────────────────────────────────────────────────────────  search_type_backward_model()  # Backward stepwise #> ── Backward Search ─────────────────────────────────────────────────── #> • display_name  'Backward Stepwise Model Search' #> ──────────────────────────────────────────────────────────────────────"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"model-type-helpers","dir":"Articles","previous_headings":"Two primary functions in featureselectr","what":"Model Type Helpers","title":"Introduction to featureselectr","text":"three main model types choose . See ?model_type.","code":"model_type_lr()  # Logistic regression #> ── Model: logistic regression ──────────────────────────────────────── #> • response    'Response' #> ──────────────────────────────────────────────────────────────────────  model_type_lm()  # Linear regression #> ── Model: linear regression ────────────────────────────────────────── #> • response    'Response' #> ──────────────────────────────────────────────────────────────────────  model_type_nb()  # Naive Bayes #> ── Model: naive Bayes ──────────────────────────────────────────────── #> • response    'Response' #> ──────────────────────────────────────────────────────────────────────"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"cost-helpers","dir":"Articles","previous_headings":"Two primary functions in featureselectr","what":"Cost Helpers","title":"Introduction to featureselectr","text":"five available cost functions, used typically need call directly. Simply pass one following string cost = argument feature_selection(). See ?feature_selection perhaps ?cost. AUC: Area curve (classification) CCC: Concordance Correlation Coefficient (regression) MSE: Mean-squared Error (regression) R2: R-squared (regression) sens/spec: Sensitivity + Specificity (sum; classification)","code":""},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"feature-selection-with-naive-bayes","dir":"Articles","previous_headings":"","what":"Feature Selection with Naive Bayes","title":"Introduction to featureselectr","text":"analysis performed simulated data set wranglr::simdata. fit Naive Bayes model feature selection. setup specifies 3 independent runs 5 fold cross-validation. Higher folds might generate slightly different results, 20-25% hold-fairly common. course, runs (repeats) take longer. 5 features significant binary classification context. identified attributes object . restrict search top 10 steps (40 total features; thus approx. 35 false positives).","code":""},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"setup-feature_select-object","dir":"Articles","previous_headings":"Feature Selection with Naive Bayes","what":"Setup feature_select Object","title":"Introduction to featureselectr","text":"","code":"data <- simdata  # True positive features attributes(data)$sig_feats$class #> [1] \"seq.2802.68\" \"seq.9251.29\" \"seq.1942.70\" \"seq.5751.80\" #> [5] \"seq.9608.12\"  # log-transform, center, and scale cs <- function(x) {   out <- log10(x)   out <- out - mean(out)   out / sd(out) }  # scramble order of feats random feats <- withr::with_seed(123, sample(helpr:::get_analytes(data))) data[, feats] <- apply(data[, feats], 2, cs)  # set model type and column name of response variable mt <- model_type_nb(response = \"class_response\")  # set search method function to 'forward' and 'model' # restrict to the top 10 steps in the search; then stop sm <- search_type_forward_model(max_steps = 10L)  # setup feature selection object fs_setup <- feature_selection(   data,   candidate_features = feats,   model_type  = mt,   search_type = sm,   runs  = 3L,   folds = 5L,   cost  = \"AUC\",   random_seed = 1 )  fs_setup #> ══ Feature Selection Object ══════════════════════════════════════════ #> ── Dataset Info ────────────────────────────────────────────────────── #> • Rows                      100 #> • Columns                   55 #> • FeatureData               40 #> ── Search Optimization Info ────────────────────────────────────────── #> • No. Candidates            '40' #> • Response Field            'class_response' #> • Cross Validation Runs     '3' #> • Cross Validation Folds    '5' #> • Stratified Folds          'FALSE' #> • Model Type                'fs_nb' #> • Search Type               'fs_forward_model' #> • Cost Function             'AUC' #> • Random Seed               '1' #> • Display Name              'Forward Stepwise Model Search' #> • Search Complete           'FALSE' #> ══════════════════════════════════════════════════════════════════════"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"perform-the-search","dir":"Articles","previous_headings":"Feature Selection with Naive Bayes","what":"Perform the Search","title":"Introduction to featureselectr","text":"S3 method Search() performs actual feature selection, method dispatch occurs depending class fs_nb.","code":"fs_nb <- Search(fs_setup)"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"plot-the-selection-paths","dir":"Articles","previous_headings":"Feature Selection with Naive Bayes","what":"Plot the Selection Paths","title":"Introduction to featureselectr","text":"S3 plot() method easily visualizes steps selection algorithm, highlights peak (AUC) models 1σ1\\sigma 2σ2\\sigma peak. 2 panels show distribution-free representation data (left; Wilcoxon signed-ranks medians) distribution dependent representation (right; standard errors means CI95%).","code":"plot(fs_nb)"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"logistic-regression","dir":"Articles","previous_headings":"","what":"Logistic Regression","title":"Introduction to featureselectr","text":"can use update() method modify existing feature_select object.","code":"fs_update <- update(   fs_setup,   # the `feature_selection` object being modified   model_type  = model_type_lr(\"class_response\"), # logistic reg   search_type = search_type_forward_model(max_steps = 15L), # increase max steps   stratify    = TRUE   # now stratify )  fs_update #> ══ Feature Selection Object ══════════════════════════════════════════ #> ── Dataset Info ────────────────────────────────────────────────────── #> • Rows                      100 #> • Columns                   55 #> • FeatureData               40 #> ── Search Optimization Info ────────────────────────────────────────── #> • No. Candidates            '40' #> • Response Field            'class_response' #> • Cross Validation Runs     '3' #> • Cross Validation Folds    '5' #> • Stratified Folds          'TRUE' #> • Model Type                'fs_lr' #> • Search Type               'fs_forward_model' #> • Cost Function             'AUC' #> • Random Seed               '1' #> • Display Name              'Forward Stepwise Model Search' #> • Search Complete           'FALSE' #> ══════════════════════════════════════════════════════════════════════"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"perform-the-search-1","dir":"Articles","previous_headings":"Logistic Regression","what":"Perform the Search","title":"Introduction to featureselectr","text":"","code":"fs_lr <- Search(fs_update)"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"plot-the-selection-algorithm","dir":"Articles","previous_headings":"Logistic Regression","what":"Plot the Selection Algorithm","title":"Introduction to featureselectr","text":"","code":"plot(fs_lr)"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"return-the-plot-features","dir":"Articles","previous_headings":"Logistic Regression","what":"Return the Plot Features","title":"Introduction to featureselectr","text":"","code":"get_fs_features(fs_lr) #> ══ Features ══════════════════════════════════════════════════════════ #> • features_max  12 #> • features_1se  8 #> • features_2se  6 #> ── features_max ────────────────────────────────────────────────────── #> 'seq.1942.70', 'seq.9297.97', 'seq.9608.12', 'seq.4914.10', 'seq.9360.55', 'seq.8142.63', 'seq.1130.49', 'seq.9373.82', 'seq.9251.29', 'seq.2802.68', 'seq.3459.49', 'seq.6356.60' #> ── features_1se ────────────────────────────────────────────────────── #> 'seq.1942.70', 'seq.9608.12', 'seq.9360.55', 'seq.8142.63', 'seq.9373.82', 'seq.9251.29', 'seq.2802.68', 'seq.3459.49' #> ── features_2se ────────────────────────────────────────────────────── #> 'seq.1942.70', 'seq.9608.12', 'seq.8142.63', 'seq.9251.29', 'seq.2802.68', 'seq.3459.49'"},{"path":"https://stufield.github.io/featureselectr/articles/featureselectr.html","id":"class-stratification-plot","dir":"Articles","previous_headings":"","what":"Class Stratification Plot","title":"Introduction to featureselectr","text":"can also check class proportions (imbalances) cross-validation folds based proportion binary classes (classification problems). evident comparing folds without forced stratification. sample plot cross-validation folds without stratification (left) update object include stratification (right):","code":"no_strat <- feature_selection(   data, candidate_features = feats,   model_type = mt, search_type = sm,   runs  = 2L, folds = 3L ) with_strat <- update(no_strat, stratify = TRUE) plot_cross(no_strat) + plot_cross(with_strat)"},{"path":"https://stufield.github.io/featureselectr/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Stu Field. Author, maintainer, copyright holder. Kirk DeLisle. Author.","code":""},{"path":"https://stufield.github.io/featureselectr/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Field S, DeLisle K (2025). featureselectr: Perform Feature Selection/Optimization. R package version 0.0.2, https://stufield.github.io/featureselectr.","code":"@Manual{,   title = {featureselectr: Perform Feature Selection/Optimization},   author = {Stu Field and Kirk DeLisle},   year = {2025},   note = {R package version 0.0.2},   url = {https://stufield.github.io/featureselectr}, }"},{"path":[]},{"path":"https://stufield.github.io/featureselectr/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Perform Feature Selection/Optimization","text":"feature selection package contains functionality designed feature selection, model building, /classifier development.","code":""},{"path":"https://stufield.github.io/featureselectr/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Perform Feature Selection/Optimization","text":"","code":"# current dev version remotes::install_github(\"stufield/featureselectr\")  # or a specific version remotes::install_github(\"stufield/featureselectr@v0.0.2\")"},{"path":"https://stufield.github.io/featureselectr/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Perform Feature Selection/Optimization","text":"load featureselectr simply make call library() usual:","code":"library(featureselectr)"},{"path":"https://stufield.github.io/featureselectr/index.html","id":"help-summary-of-the-package","dir":"","previous_headings":"","what":"Help summary of the package","title":"Perform Feature Selection/Optimization","text":"","code":"library(help = featureselectr)"},{"path":"https://stufield.github.io/featureselectr/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Perform Feature Selection/Optimization","text":"See vignette(\"featureselectr\") usage examples.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Selection Search Algorithms — Search","title":"Feature Selection Search Algorithms — Search","text":"step-wise search methods can used identify locally optimal model complexity greedy search. methods either build (forward) break (backward) model one covariate time based upon results \"Runs\" \"Folds\" cross-validation sets, .e. 5 runs 5-fold cross-validation, 25 evaluations made determine covariate yields best average performance (given cost function). See Details information options.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Selection Search Algorithms — Search","text":"","code":"Search(x, num_cores)"},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Selection Search Algorithms — Search","text":"x feature_select class object call call feature_selection(). num_cores integer(1). many cores use search. Defaults 1L, use parallel processing. Values > 1 available Linux systems. Note parallel processing implemented runs(!), choose cores appropriately.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature Selection Search Algorithms — Search","text":"\"feature_select\" class object; list : data original feature data use. candidate_features list candidate features. model_type list containing model type variables appropriate class desired model type. search_type list containing search type variables appropriate class desired search type. cost string type cost function. cost_fxn list containing cost variables appropriate class desired object cost function. runs number runs. folds number folds. random_seed random seed used cross_val list containing training test indices various cross validation folds. search_complete Logical object completed search call original matched call.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Feature Selection Search Algorithms — Search","text":"currently 2 search options, \"greedy\" algorithms: Forward Model Search: covariate found first step carries steps. Likewise, second covariate found (combination first) also carries . results single model determined locally optimal based upon performances across runs folds. Backward Model Search: covariate removed first step eliminated steps. result single model determined locally optimal based upon performances across runs folds.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"silence-notches","dir":"Reference","previous_headings":"","what":"Silence notches","title":"Feature Selection Search Algorithms — Search","text":"plot() routine, Notch went outside hinges message often triggered ggplot2. can silenced setting global options: options(rlib_message_verbosity = \"quiet\")","code":""},{"path":[]},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Feature Selection Search Algorithms — Search","text":"Stu Field, Kirk DeLisle","code":""},{"path":"https://stufield.github.io/featureselectr/reference/Search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature Selection Search Algorithms — Search","text":"","code":"data <- wranglr::simdata  # Setup response variable data$class_response <- as.factor(data$class_response) mt  <- model_type_lr(\"class_response\") sm  <- search_type_forward_model(\"Forward Selection Algorithm\", 10L) ft  <- head(helpr:::get_analytes(data))  # select candidate features mcp <- feature_selection(data,                          candidate_features = ft,                          model_type = mt,                          search_type = sm,                          cost = \"AUC\",                          runs = 4L, folds = 3L,                          random_seed = 101L)  fs <- Search(mcp) #> ℹ Starting the Feature Selection algorithm ... #> ── Using `Forward-Stepwise` model search ────────────────────────────── #> ℹ Step 1 of 6 #> ℹ Step 2 of 6 #> ℹ Step 3 of 6 #> ℹ Step 4 of 6 #> ℹ Step 5 of 6 #> ℹ Step 6 of 6 fs #> ══ Feature Selection Object ═══════════════════════════════════════════ #> ── Dataset Info ─────────────────────────────────────────────────────── #> • Rows                      100 #> • Columns                   55 #> • FeatureData               6 #> ── Search Optimization Info ─────────────────────────────────────────── #> • No. Candidates            '6' #> • Response Field            'class_response' #> • Cross Validation Runs     '4' #> • Cross Validation Folds    '3' #> • Stratified Folds          'FALSE' #> • Model Type                'fs_lr' #> • Search Type               'fs_forward_model' #> • Cost Function             'AUC' #> • Random Seed               '101' #> • Display Name              'Forward Selection Algorithm' #> • Search Complete           'TRUE' #> ═══════════════════════════════════════════════════════════════════════  plot(fs) #> Notch went outside hinges #> ℹ Do you want `notch = FALSE`? #> Notch went outside hinges #> ℹ Do you want `notch = FALSE`? #> Notch went outside hinges #> ℹ Do you want `notch = FALSE`? #> Notch went outside hinges #> ℹ Do you want `notch = FALSE`? #> Notch went outside hinges #> ℹ Do you want `notch = FALSE`?   # Using parallel processing: #   should be ~4x faster than above if (FALSE) { # \\dontrun{   fs <- Search(mcp, num_cores = 4L) } # }"},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature Selection Object Declaration — feature_selection","title":"Feature Selection Object Declaration — feature_selection","text":"Declares generates feature_selection class object within Feature Selection framework. object acts holder data (bootstrapped cross-validation folds), model type, search type, cost function, underlying data structure use functions.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature Selection Object Declaration — feature_selection","text":"","code":"feature_selection(   data,   candidate_features,   model_type,   search_type,   runs = 1L,   folds = 1L,   cost = c(\"AUC\", \"R2\", \"CCC\", \"MSE\", \"sens\", \"spec\"),   bootstrap = FALSE,   stratify = FALSE,   strat_column = NULL,   random_seed = 101L )  # S3 method for class 'feature_select' print(x, ...)  is_feature_select(x)  # S3 method for class 'feature_select' update(object, ...)"},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature Selection Object Declaration — feature_selection","text":"data data.frame containing features clinical data suitable modeling. candidate_features character(n). List candidate features, .e. columns names, data object. model_type instantiated model_type object, generated via call one model_type() functions. search_type instantiated search_type object, generated via call one search_type() functions. runs integer(1). many runs (repeats) perform. folds integer(1). many fold cross-validation perform. cost character(1). string used defining cost function. One : AUC Area Curve MSE Mean-Squared Error CCC Concordance Correlation Coefficient R2 R-squared - regression models sens spec Sensitivity + Specificity bootstrap logical(1). data bootstrapped rather set cross-validation folds? result multiple runs (defined runs) 1 Fold . full data set sampled replacement generate training set equivalent size. samples chosen sampling make test set. stratify logical(1). cross-validation folds stratified based upon column specified strat_column? strat_column character(1). column use stratification cross-validation. NULL (default), column name corresponding response parameter ?model_type used. random_seed integer(1). Used control random number generator reproducibility. x, object feature_select class object. ... Arguments declared update argument = value format. Non-declared arguments original call preserved.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature Selection Object Declaration — feature_selection","text":"\"feature_select\" class object; list : data original feature data use. candidate_features list candidate features. model_type list containing model type variables appropriate class desired model type. search_type list containing search type variables appropriate class desired search type. cost string type cost function. cost_fxn list containing cost variables appropriate class desired object cost function. runs number runs. folds number folds. random_seed random seed used cross_val list containing training test indices various cross validation folds. search_complete Logical object completed search call original matched call.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Feature Selection Object Declaration — feature_selection","text":"is_feature_select(): Check valid feature_select class object.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Feature Selection Object Declaration — feature_selection","text":"Hastie, Tibshirani, Friedman. Elements Statistical Learning: Data Mining, Inference, Prediction. 2nd Ed. Springer. 2009.","code":""},{"path":[]},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Feature Selection Object Declaration — feature_selection","text":"Stu Field, Kirk DeLisle","code":""},{"path":"https://stufield.github.io/featureselectr/reference/feature_selection.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature Selection Object Declaration — feature_selection","text":"","code":"# Simulated Test Data data <- wranglr::simdata  # Setup response variable data$class_response <- factor(data$class_response)  mt <- model_type_lr(\"class_response\") sm <- search_type_forward_model(15L, display_name = \"Forward Algorithm\") ft <- helpr:::get_analytes(data)   # select candidate features fs <- feature_selection(data, candidate_features = ft,                         model_type = mt, search_type = sm, cost = \"sens\",                         runs = 5L, folds = 5L) # S3 Print method fs #> ══ Feature Selection Object ═══════════════════════════════════════════ #> ── Dataset Info ─────────────────────────────────────────────────────── #> • Rows                      100 #> • Columns                   55 #> • FeatureData               40 #> ── Search Optimization Info ─────────────────────────────────────────── #> • No. Candidates            '40' #> • Response Field            'class_response' #> • Cross Validation Runs     '5' #> • Cross Validation Folds    '5' #> • Stratified Folds          'FALSE' #> • Model Type                'fs_lr' #> • Search Type               'fs_forward_model' #> • Cost Function             'sens' #> • Random Seed               '101' #> • Display Name              'Forward Algorithm' #> • Search Complete           'FALSE' #> ═══════════════════════════════════════════════════════════════════════  # Using the S3 Update method to modify existing `feature_select` object: #   change model type, cost function, and random seed fs2 <- update(fs, model_type = model_type_nb(\"class_response\"),               cost = \"AUC\", random_seed = 99L) fs2 #> ══ Feature Selection Object ═══════════════════════════════════════════ #> ── Dataset Info ─────────────────────────────────────────────────────── #> • Rows                      100 #> • Columns                   55 #> • FeatureData               40 #> ── Search Optimization Info ─────────────────────────────────────────── #> • No. Candidates            '40' #> • Response Field            'class_response' #> • Cross Validation Runs     '5' #> • Cross Validation Folds    '5' #> • Stratified Folds          'FALSE' #> • Model Type                'fs_nb' #> • Search Type               'fs_forward_model' #> • Cost Function             'AUC' #> • Random Seed               '99' #> • Display Name              'Forward Algorithm' #> • Search Complete           'FALSE' #> ═══════════════════════════════════════════════════════════════════════  # change number of runs & folds #   requires re-calculation of cross-validation parameters fs3 <- update(fs, runs = 20L, folds = 10L) fs3 #> ══ Feature Selection Object ═══════════════════════════════════════════ #> ── Dataset Info ─────────────────────────────────────────────────────── #> • Rows                      100 #> • Columns                   55 #> • FeatureData               40 #> ── Search Optimization Info ─────────────────────────────────────────── #> • No. Candidates            '40' #> • Response Field            'class_response' #> • Cross Validation Runs     '20' #> • Cross Validation Folds    '10' #> • Stratified Folds          'FALSE' #> • Model Type                'fs_lr' #> • Search Type               'fs_forward_model' #> • Cost Function             'sens' #> • Random Seed               '101' #> • Display Name              'Forward Algorithm' #> • Search Complete           'FALSE' #> ═══════════════════════════════════════════════════════════════════════"},{"path":"https://stufield.github.io/featureselectr/reference/featureselectr-package.html","id":null,"dir":"Reference","previous_headings":"","what":"featureselectr: Perform Feature Selection/Optimization — featureselectr-package","title":"featureselectr: Perform Feature Selection/Optimization — featureselectr-package","text":"object oriented package containing functionality designed feature selection, model building, /classifier development.","code":""},{"path":[]},{"path":"https://stufield.github.io/featureselectr/reference/featureselectr-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"featureselectr: Perform Feature Selection/Optimization — featureselectr-package","text":"Maintainer: Stu Field stu.g.field@gmail.com (ORCID) [copyright holder] Authors: Kirk DeLisle rkdelisle@gmail.com","code":""},{"path":"https://stufield.github.io/featureselectr/reference/get_fs_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Feature Selection Markers — get_fs_features","title":"Get Feature Selection Markers — get_fs_features","text":"Returns maximum, se1, se2 features completed feature_select object.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/get_fs_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Feature Selection Markers — get_fs_features","text":"","code":"get_fs_features(x)"},{"path":"https://stufield.github.io/featureselectr/reference/get_fs_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Feature Selection Markers — get_fs_features","text":"x feature_select class object call call feature_selection().","code":""},{"path":"https://stufield.github.io/featureselectr/reference/get_fs_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Feature Selection Markers — get_fs_features","text":"list containing: features_max Combination features gives maximum/minimum mean cost function. features_1se Combination features mean cost function one standard error (SE) maximum/minimum mean cost function. features_2se Combination features mean cost function 1.96*SE maximum/minimum mean cost function.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/get_fs_features.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get Feature Selection Markers — get_fs_features","text":"","code":"data  <- wranglr::simdata feats <- attr(data, \"sig_feats\")$class fs <- feature_selection(data, candidate_features = feats,                         search_type = search_type_forward_model(),                         model_type  = model_type_lr(\"class_response\"),                         runs = 2L, folds = 2L) fs_obj <- Search(fs) #> ℹ Starting the Feature Selection algorithm ... #> ── Using `Forward-Stepwise` model search ────────────────────────────── #> ℹ Step 1 of 5 #> ℹ Step 2 of 5 #> ℹ Step 3 of 5 #> ℹ Step 4 of 5 #> ℹ Step 5 of 5 get_fs_features(fs_obj) #> ══ Features ═══════════════════════════════════════════════════════════ #> • features_max  5 #> • features_1se  3 #> • features_2se  2 #>  #> ── features_max ─────────────────────────────────────────────────────── #> 'seq.2802.68', 'seq.9251.29', 'seq.1942.70', 'seq.5751.80', 'seq.9608.12' #> ── features_1se ─────────────────────────────────────────────────────── #> 'seq.2802.68', 'seq.9251.29', 'seq.1942.70' #> ── features_2se ─────────────────────────────────────────────────────── #> 'seq.9251.29', 'seq.1942.70'"},{"path":"https://stufield.github.io/featureselectr/reference/model_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Model Type Object Definitions — model_type","title":"Create Model Type Object Definitions — model_type","text":"Declares model type Feature Selection framework. currently 3 model type options: Logistic Regression Models (lr) Linear Regression Models (lm) Naive Bayes Models (nb) Typically functions can called defaults, especially called upon tr_data class object (see libml).","code":""},{"path":"https://stufield.github.io/featureselectr/reference/model_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Model Type Object Definitions — model_type","text":"","code":"model_type_lr(response = \"Response\")  model_type_nb(response = \"Response\")  model_type_lm(response = \"Response\")"},{"path":"https://stufield.github.io/featureselectr/reference/model_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Model Type Object Definitions — model_type","text":"response character(1). string column name use response variable. Assumed binary factor type unless linear regression desired.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/model_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Model Type Object Definitions — model_type","text":"object appropriate class according model type chosen, one : fs_lr, fs_nb, fs_lm.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/model_type.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create Model Type Object Definitions — model_type","text":"Stu Field, Kirk DeLisle","code":""},{"path":"https://stufield.github.io/featureselectr/reference/model_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Model Type Object Definitions — model_type","text":"","code":"# Logistic Regression model_type_lr() #> ── Model: logistic regression ───────────────────────────────────────── #> • response    'Response' #> ───────────────────────────────────────────────────────────────────────  # Robust Parameter Naive Bayes (default) model_type_nb() #> ── Model: naive Bayes ───────────────────────────────────────────────── #> • response    'Response' #> ───────────────────────────────────────────────────────────────────────  # Linear Regression model_type_lm() #> ── Model: linear regression ─────────────────────────────────────────── #> • response    'Response' #> ───────────────────────────────────────────────────────────────────────"},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Model Search Object Definitions — search_type_backward_model","title":"Create Model Search Object Definitions — search_type_backward_model","text":"Functions creating model type definitions objects Feature Selection framework. Current available search types/methods : forward step-wise model backward step-wise model information called within object creation modify attributes (class) reflect appropriate search values.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Model Search Object Definitions — search_type_backward_model","text":"","code":"search_type_backward_model(display_name = \"Backward Stepwise Model Search\")  search_type_forward_model(   display_name = \"Forward Stepwise Model Search\",   max_steps = 20L )"},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Model Search Object Definitions — search_type_backward_model","text":"display_name character(1). title used S3 plot methods. max_steps integer(1). Maximum number features allowed model.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Model Search Object Definitions — search_type_backward_model","text":"list containing: display_name official \"Title\" used downstream plot methods called feature_select object. max_steps Maximum model steps search. Forward search !","code":""},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Create Model Search Object Definitions — search_type_backward_model","text":"search_type_backward_model(): Backward model selection search. search_type_forward_model(): Forward model selection search.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Create Model Search Object Definitions — search_type_backward_model","text":"Stu Field, Kirk DeLisle","code":""},{"path":"https://stufield.github.io/featureselectr/reference/search_type.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create Model Search Object Definitions — search_type_backward_model","text":"","code":"search_type_forward_model()                    # the default = 20L #> ── Forward Search ───────────────────────────────────────────────────── #> • display_name  'Forward Stepwise Model Search' #> • max_steps     20 #> ───────────────────────────────────────────────────────────────────────  search_type_forward_model(max_steps = 15L)     # set to 15 #> ── Forward Search ───────────────────────────────────────────────────── #> • display_name  'Forward Stepwise Model Search' #> • max_steps     15 #> ───────────────────────────────────────────────────────────────────────  search_type_forward_model(\"My Forward Search\") # set a display title #> ── Forward Search ───────────────────────────────────────────────────── #> • display_name  'My Forward Search' #> • max_steps     20 #> ───────────────────────────────────────────────────────────────────────"},{"path":"https://stufield.github.io/featureselectr/reference/setup_cross.html","id":null,"dir":"Reference","previous_headings":"","what":"Set up Cross-Validation Folds — setup_cross","title":"Set up Cross-Validation Folds — setup_cross","text":"S3 methods set internal cross-validation. Methods exist stratified non-stratified scenarios. Since mostly internal methods, documentation minimal. stratified version S3 method sets internal cross-validation stratified folds. Stratified implies structure (proportions) response variable maintained (.e. proportion disease samples fold comparable disease proportion full training set). plotting routine allows one visually check cross-validation stratification bias.","code":""},{"path":"https://stufield.github.io/featureselectr/reference/setup_cross.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set up Cross-Validation Folds — setup_cross","text":"","code":"setup_cross(x)  setup_cross_strat(x)  plot_cross(x)"},{"path":"https://stufield.github.io/featureselectr/reference/setup_cross.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set up Cross-Validation Folds — setup_cross","text":"x feature_select class object call call feature_selection().","code":""},{"path":"https://stufield.github.io/featureselectr/reference/setup_cross.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set up Cross-Validation Folds — setup_cross","text":"Stu Field","code":""},{"path":"https://stufield.github.io/featureselectr/news/index.html","id":"featureselectr-002","dir":"Changelog","previous_headings":"","what":"featureselectr 0.0.2","title":"featureselectr 0.0.2","text":"Intermediate release allow tag download","code":""},{"path":"https://stufield.github.io/featureselectr/news/index.html","id":"featureselectr-0019001","dir":"Changelog","previous_headings":"","what":"featureselectr 0.0.1.9001","title":"featureselectr 0.0.1.9001","text":"Future development … mostly internal documentation","code":""},{"path":"https://stufield.github.io/featureselectr/news/index.html","id":"featureselectr-001","dir":"Changelog","previous_headings":"","what":"featureselectr 0.0.1","title":"featureselectr 0.0.1","text":"Initial Release!","code":""}]
